# PlushPal Study

## What is PlushPal?
[PlushPal](https://ttseng.github.io/plushie/) is a new digital tool for kids to use make their stuffed animals interactive using machine learning (ML). Kids make their own custom gesture and sound pairings, and use a [micro:bit](https://microbit.org) to detect specific movements that their stuffed animal makes. 

![plushpal gif](/img/plushpal-demo.gif){: width="400" }

## How it Works
### Set-up

![set up micro:bit](/img/set-up.png){: width="250" }

Start by attaching a micro:bit to a stuffed animal and pair it to PlushPal using web Bluetooth.

### Record Gestures

![record gestures](/img/record-gestures.png){: width="400" }

Create a new gesture and perform the gesture multiple times while recording it.

### Evaluate and Play

![evaluate and play](/img/evaluate.png){: width="250" }

Test if ML models correctly detect gestures and make adjustments as needed and add sound to each gesture.

## What is the PlushPal study?
PlushPal was introduced to eleven kids, ages 8-14 years old, over Zoom and in person during the COVID-19 pandemic. Children brought their own stuffed animals to the playtest and used a micro:bit and PlushPal to make their toys interactive. After a brief introduction to the tool, machine learning, and a presurvey, children were asked to make asked to make create custom gestures for their stuffed animals (ex. walking, eating, sleeping). These gestures were performed multiple times by the children, and it was suggested that they should perform and record each gesture at least three times. 

## Demographics

![demographics](/img/demographics.png){: width="400" }

## What Kids Made

In the eleven projects that kids made, there were 42 unique gestures that were created. Some gestures were common amongst projects (ex: run and jump) and others were unique only to one project.

<iframe width="100%" height="109" frameborder="0"
  src="https://observablehq.com/embed/@deannagelosi/plushpal-gesture-visualization?cells=swatch"></iframe>

<html>
  <iframe width="945px" height="984px" frameborder="0" src="https://observablehq.com/embed/@deannagelosi/plushpal-gesture-visualization?cells=NodesAndLabels"></iframe>
</html>

## Case Studies

<div class='tableauPlaceholder' id='viz1619886289792' style='position: relative'>
  <noscript>
    <a href='#'>
      <img alt='Brian Bear&#39;s Gesture Log ' src='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;Br&#47;BrianBear&#47;BrianBear&#47;1_rss.png' style='border: none' />
    </a>
  </noscript>
  <object class='tableauViz'  style='display:none;'><param name='host_url' value='https%3A%2F%2Fpublic.tableau.com%2F' /> 
    <param name='embed_code_version' value='3' /> 
    <param name='site_root' value='' />
    <param name='name' value='BrianBear&#47;BrianBear' />
    <param name='tabs' value='no' />
    <param name='toolbar' value='yes' />
    <param name='static_image' value='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;Br&#47;BrianBear&#47;BrianBear&#47;1.png' /> 
    <param name='animate_transition' value='yes' />
    <param name='display_static_image' value='yes' />
    <param name='display_spinner' value='yes' />
    <param name='display_overlay' value='yes' />
    <param name='display_count' value='yes' />
    <param name='language' value='en' />
  </object>
</div>   

![Brian Bear accelerometer data](/img/brian-bear-accel.png){: width="250" }


<script type='text/javascript'>
  var divElement = document.getElementById('viz1619886289792');
  var vizElement = divElement.getElementsByTagName('object')[0];
  vizElement.style.width='100%';
  vizElement.style.height=(divElement.offsetWidth*0.75)+'px';
  var scriptElement = document.createElement('script');
  scriptElement.src = 'https://public.tableau.com/javascripts/api/viz_v1.js';
  vizElement.parentNode.insertBefore(scriptElement, vizElement);
</script>

## Findings
![data literacy](/img/data literacy.png){: width="400" }
